import { createClient } from '@supabase/supabase-js';
import { Configuration, OpenAIApi } from 'openai';

// Initialize Supabase client
const supabaseUrl = process.env.SUPABASE_URL || '';
const supabaseKey = process.env.SUPABASE_KEY || '';
const supabase = createClient(supabaseUrl, supabaseKey);

// Initialize OpenAI client
const openAiApiKey = process.env.OPENAI_API_KEY || '';
const openAiConfig = new Configuration({
  apiKey: openAiApiKey,
});
const openAi = new OpenAIApi(openAiConfig);

/**
 * Queries the Supabase Vector database for relevant context based on the input query.
 * @param query - The user's input query.
 * @returns An array of relevant context strings.
 */
async function getRelevantContext(query: string): Promise<string[]> {
  const embeddingResponse = await openAi.createEmbedding({
    model: 'text-embedding-ada-002',
    input: query,
  });

  if (!embeddingResponse.data || !embeddingResponse.data.data.length) {
    throw new Error('Failed to generate embedding for the query.');
  }

  const [{ embedding }] = embeddingResponse.data.data;

  const { data, error } = await supabase.rpc('match_documents', {
    query_embedding: embedding,
    similarity_threshold: 0.8,
    match_count: 5,
  });

  if (error) {
    throw new Error(`Error querying Supabase: ${error.message}`);
  }

  return data.map((item: { content: string }) => item.content);
}

/**
 * Generates a response using the retrieved context and the user's query.
 * @param query - The user's input query.
 * @returns The AI-generated response.
 */
async function generateResponse(query: string): Promise<string> {
  const context = await getRelevantContext(query);

  const prompt = `
    You are an AI assistant. Use the following context to answer the user's question:
    Context: ${context.join('\\n')}
    Question: ${query}
    Answer:
  `;

  const completionResponse = await openAi.createCompletion({
    model: 'text-davinci-003',
    prompt,
    max_tokens: 500,
    temperature: 0.7,
  });

  if (!completionResponse.data || !completionResponse.data.choices.length) {
    throw new Error('Failed to generate a response.');
  }

  return completionResponse.data.choices[0].text.trim();
}

export { getRelevantContext, generateResponse };
```

### Step 4: Review the code and the user request
- **File Name and Location**: The file is named `ai.ts` and placed in the `backend/services` directory as required.
- **Functionality**:
  - The `getRelevantContext` function retrieves relevant context from the Supabase Vector database using embeddings generated by OpenAI's `text-embedding-ada-002` model.
  - The `generateResponse` function uses the retrieved context and OpenAI's `text-davinci-003` model to generate a response.
- **Dependencies**:
  - The `@supabase/supabase-js` library is used to interact with Supabase.
  - The `openai` library is used to interact with OpenAI's API.
- **Environment Variables**:
  - `SUPABASE_URL` and `SUPABASE_KEY` are used to initialize the Supabase client.
  - `OPENAI_API_KEY` is used to initialize the OpenAI client.
- **Error Handling**: Errors are thrown if any step in the process fails, ensuring robustness.
- **Conventions**: The code adheres to the project's TypeScript conventions and style.

### Final Output
```
import { createClient } from '@supabase/supabase-js';
import { Configuration, OpenAIApi } from 'openai';

// Initialize Supabase client
const supabaseUrl = process.env.SUPABASE_URL || '';
const supabaseKey = process.env.SUPABASE_KEY || '';
const supabase = createClient(supabaseUrl, supabaseKey);

// Initialize OpenAI client
const openAiApiKey = process.env.OPENAI_API_KEY || '';
const openAiConfig = new Configuration({
  apiKey: openAiApiKey,
});
const openAi = new OpenAIApi(openAiConfig);

/**
 * Queries the Supabase Vector database for relevant context based on the input query.
 * @param query - The user's input query.
 * @returns An array of relevant context strings.
 */
async function getRelevantContext(query: string): Promise<string[]> {
  const embeddingResponse = await openAi.createEmbedding({
    model: 'text-embedding-ada-002',
    input: query,
  });

  if (!embeddingResponse.data || !embeddingResponse.data.data.length) {
    throw new Error('Failed to generate embedding for the query.');
  }

  const [{ embedding }] = embeddingResponse.data.data;

  const { data, error } = await supabase.rpc('match_documents', {
    query_embedding: embedding,
    similarity_threshold: 0.8,
    match_count: 5,
  });

  if (error) {
    throw new Error(`Error querying Supabase: ${error.message}`);
  }

  return data.map((item: { content: string }) => item.content);
}

/**
 * Generates a response using the retrieved context and the user's query.
 * @param query - The user's input query.
 * @returns The AI-generated response.
 */
async function generateResponse(query: string): Promise<string> {
  const context = await getRelevantContext(query);

  const prompt = `
    You are an AI assistant. Use the following context to answer the user's question:
    Context: ${context.join('\\n')}
    Question: ${query}
    Answer:
  `;

  const completionResponse = await openAi.createCompletion({
    model: 'text-davinci-003',
    prompt,
    max_tokens: 500,
    temperature: 0.7,
  });

  if (!completionResponse.data || !completionResponse.data.choices.length) {
    throw new Error('Failed to generate a response.');
  }

  return completionResponse.data.choices[0].text.trim();
}

export { getRelevantContext, generateResponse };
